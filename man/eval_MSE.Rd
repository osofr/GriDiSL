% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SuperLearner_main.R
\name{eval_MSE}
\alias{eval_MSE}
\title{Evaluate MSE for model fits, possibly using new data}
\usage{
eval_MSE(modelfit, newdata, subset_idx = NULL,
  verbose = getOption("longGriDiSL.verbose"))
}
\arguments{
\item{modelfit}{Model fit object returned by \code{\link{fit_model}} function.}

\item{newdata}{...}

\item{subset_idx}{...}

\item{verbose}{Set to \code{TRUE} to print messages on status and information to the console. Turn this on by default using \code{options(longGriDiSL.verbose=TRUE)}.}
}
\value{
...
}
\description{
By default this function will extract out-of-sample predictions from original training data (automatically done by h2o) to evaluate the cross-validated MSE.
However, when \code{newdata} is supplied, the predictions for each CV model will be based on this external validation dataset.
These predictions and the outcome stored in \code{newdata} are then used to re-evalute the CV MSE. Note that \code{newdata} must be of the same
dimensionality as the original training data used for fitting the h2o models.
}

