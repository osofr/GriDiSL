% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ModelXGBoostGridLearner.R
\name{xgb.grid}
\alias{xgb.grid}
\title{Hyper-parameter grid search for xgboost}
\usage{
xgb.grid(param_grid, data, nrounds, nfold, label = NULL, missing = NA,
  prediction = FALSE, showsd = TRUE, metrics = list(), obj = NULL,
  feval = NULL, stratified = TRUE, folds = NULL, verbose = TRUE,
  early_stopping_rounds = NULL, maximize = NULL, callbacks = list(),
  search_criteria, seed = NULL, order_metric_name = NULL,
  validation_data = NULL, ...)
}
\arguments{
\item{param_grid}{A named list with xgboost parameter names, consisting of vectors of hyper-parameter values.
The dataset containing the grid of possible hyper-parameters for model
training is formed internally by running \code{purrr::cross_d(param_grid)}.}

\item{data}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{nrounds}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{nfold}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{label}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{missing}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{prediction}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{showsd}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{metrics}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{obj}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{feval}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{stratified}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{folds}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{verbose}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{early_stopping_rounds}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{maximize}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{callbacks}{Same as in \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}

\item{search_criteria}{Define how to search over the grid of hyper-parameters.
This should be the list with parameters controlling the grid search.
Currently supported parameters are: \code{'strategy'} and \code{'max_models'}.
Currently supported values for \code{strategy} are \code{'Cartesian'} (covers the entire space of hyper-parameter combinations) or
\code{'RandomDiscrete'} (do a random search of all the combinations of hyper-parameters).
\code{'max_models'} parameter can be set to an integer >0 that defines the maximum number of models to be trained.}

\item{seed}{Specify the seed to use for determining the random model order in random grid search.}

\item{order_metric_name}{What is the name of the metric for ranking the final grid of model fits?}

\item{validation_data}{Validation data to score the model performance while training with \code{xgboost::xgb.train}.
Must be in the same format as \code{data}, see \code{?xgboost::xgb.train} for additional information.}

\item{...}{Other parameters passed on directly to either \code{xgboost::xgb.train} or \code{xgboost::xgb.cv}.}
}
\value{
A resulting grid search of model object fits in a form of a \code{data.table} with \code{xgboost} model fit
objects saved in a list column named \code{'xgb_fit'}.
In addition, the output \code{data.table} contains the original hyper-parameters used as well as the model
performance metrics assessed by \code{xgboost}. The dataset is sorted according to the \code{order_metric_name}.
}
\description{
Performing simple hyper-parameter grid search for xgboost. Model scoring can be
done either with validation data or with V-fold cross-validation.
}
\author{
The code for using \code{tidyverse} syntax for model grid search is borrowed and adapted from:
\href{https://drsimonj.svbtle.com/grid-search-in-the-tidyverse}{https://drsimonj.svbtle.com/grid-search-in-the-tidyverse}.
The \code{search_criteria} idea is borrowed from \code{h2o::h2o.grid}.
}

